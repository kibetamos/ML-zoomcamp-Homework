{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JAMB_Score</th>\n",
       "      <th>Study_Hours_Per_Week</th>\n",
       "      <th>Attendance_Rate</th>\n",
       "      <th>Teacher_Quality</th>\n",
       "      <th>Distance_To_School</th>\n",
       "      <th>School_Type</th>\n",
       "      <th>School_Location</th>\n",
       "      <th>Extra_Tutorials</th>\n",
       "      <th>Access_To_Learning_Materials</th>\n",
       "      <th>Parent_Involvement</th>\n",
       "      <th>IT_Knowledge</th>\n",
       "      <th>Student_ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Socioeconomic_Status</th>\n",
       "      <th>Parent_Education_Level</th>\n",
       "      <th>Assignments_Completed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>192</td>\n",
       "      <td>22</td>\n",
       "      <td>78</td>\n",
       "      <td>4</td>\n",
       "      <td>12.4</td>\n",
       "      <td>Public</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>High</td>\n",
       "      <td>Medium</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>Male</td>\n",
       "      <td>Low</td>\n",
       "      <td>Tertiary</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>207</td>\n",
       "      <td>14</td>\n",
       "      <td>88</td>\n",
       "      <td>4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>Public</td>\n",
       "      <td>Rural</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>Male</td>\n",
       "      <td>High</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>182</td>\n",
       "      <td>29</td>\n",
       "      <td>87</td>\n",
       "      <td>2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>Public</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>High</td>\n",
       "      <td>Medium</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>Female</td>\n",
       "      <td>High</td>\n",
       "      <td>Tertiary</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>210</td>\n",
       "      <td>29</td>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>2.6</td>\n",
       "      <td>Public</td>\n",
       "      <td>Urban</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Medium</td>\n",
       "      <td>High</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>Female</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tertiary</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>199</td>\n",
       "      <td>12</td>\n",
       "      <td>98</td>\n",
       "      <td>3</td>\n",
       "      <td>8.8</td>\n",
       "      <td>Public</td>\n",
       "      <td>Urban</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>Female</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tertiary</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>183</td>\n",
       "      <td>20</td>\n",
       "      <td>74</td>\n",
       "      <td>2</td>\n",
       "      <td>10.6</td>\n",
       "      <td>Public</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "      <td>4996</td>\n",
       "      <td>16</td>\n",
       "      <td>Male</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Primary</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>179</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Public</td>\n",
       "      <td>Rural</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>4997</td>\n",
       "      <td>22</td>\n",
       "      <td>Male</td>\n",
       "      <td>Low</td>\n",
       "      <td>Secondary</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>261</td>\n",
       "      <td>17</td>\n",
       "      <td>89</td>\n",
       "      <td>3</td>\n",
       "      <td>11.3</td>\n",
       "      <td>Public</td>\n",
       "      <td>Urban</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Low</td>\n",
       "      <td>High</td>\n",
       "      <td>4998</td>\n",
       "      <td>18</td>\n",
       "      <td>Male</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Primary</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>183</td>\n",
       "      <td>15</td>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "      <td>15.9</td>\n",
       "      <td>Public</td>\n",
       "      <td>Rural</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Low</td>\n",
       "      <td>Medium</td>\n",
       "      <td>4999</td>\n",
       "      <td>18</td>\n",
       "      <td>Male</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Secondary</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>218</td>\n",
       "      <td>34</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Public</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>5000</td>\n",
       "      <td>16</td>\n",
       "      <td>Female</td>\n",
       "      <td>High</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      JAMB_Score  Study_Hours_Per_Week  Attendance_Rate  Teacher_Quality  \\\n",
       "0            192                    22               78                4   \n",
       "1            207                    14               88                4   \n",
       "2            182                    29               87                2   \n",
       "3            210                    29               99                2   \n",
       "4            199                    12               98                3   \n",
       "...          ...                   ...              ...              ...   \n",
       "4995         183                    20               74                2   \n",
       "4996         179                     0               80                2   \n",
       "4997         261                    17               89                3   \n",
       "4998         183                    15               96                2   \n",
       "4999         218                    34              100                1   \n",
       "\n",
       "      Distance_To_School School_Type School_Location Extra_Tutorials  \\\n",
       "0                   12.4      Public           Urban             Yes   \n",
       "1                    2.7      Public           Rural              No   \n",
       "2                    9.6      Public           Rural             Yes   \n",
       "3                    2.6      Public           Urban              No   \n",
       "4                    8.8      Public           Urban              No   \n",
       "...                  ...         ...             ...             ...   \n",
       "4995                10.6      Public           Urban             Yes   \n",
       "4996                20.0      Public           Rural              No   \n",
       "4997                11.3      Public           Urban              No   \n",
       "4998                15.9      Public           Rural              No   \n",
       "4999                 7.0      Public           Urban             Yes   \n",
       "\n",
       "     Access_To_Learning_Materials Parent_Involvement IT_Knowledge  Student_ID  \\\n",
       "0                             Yes               High       Medium           1   \n",
       "1                             Yes               High         High           2   \n",
       "2                             Yes               High       Medium           3   \n",
       "3                             Yes             Medium         High           4   \n",
       "4                             Yes             Medium       Medium           5   \n",
       "...                           ...                ...          ...         ...   \n",
       "4995                           No                Low          Low        4996   \n",
       "4996                          Yes             Medium       Medium        4997   \n",
       "4997                           No                Low         High        4998   \n",
       "4998                           No                Low       Medium        4999   \n",
       "4999                          Yes             Medium       Medium        5000   \n",
       "\n",
       "      Age  Gender Socioeconomic_Status Parent_Education_Level  \\\n",
       "0      17    Male                  Low               Tertiary   \n",
       "1      15    Male                 High                    NaN   \n",
       "2      20  Female                 High               Tertiary   \n",
       "3      22  Female               Medium               Tertiary   \n",
       "4      22  Female               Medium               Tertiary   \n",
       "...   ...     ...                  ...                    ...   \n",
       "4995   16    Male               Medium                Primary   \n",
       "4996   22    Male                  Low              Secondary   \n",
       "4997   18    Male               Medium                Primary   \n",
       "4998   18    Male               Medium              Secondary   \n",
       "4999   16  Female                 High                    NaN   \n",
       "\n",
       "      Assignments_Completed  \n",
       "0                         2  \n",
       "1                         1  \n",
       "2                         2  \n",
       "3                         1  \n",
       "4                         1  \n",
       "...                     ...  \n",
       "4995                      2  \n",
       "4996                      1  \n",
       "4997                      3  \n",
       "4998                      1  \n",
       "4999                      2  \n",
       "\n",
       "[5000 rows x 17 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer  # Updated import\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "url = 'https://github.com/alexeygrigorev/datasets/raw/refs/heads/master/jamb_exam_results.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-2.1.2-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in ./env/lib/python3.12/site-packages (from xgboost) (2.1.2)\n",
      "Collecting nvidia-nccl-cu12 (from xgboost)\n",
      "  Downloading nvidia_nccl_cu12-2.23.4-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: scipy in ./env/lib/python3.12/site-packages (from xgboost) (1.14.1)\n",
      "Downloading xgboost-2.1.2-py3-none-manylinux_2_28_x86_64.whl (153.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.9/153.9 MB\u001b[0m \u001b[31m754.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:05\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.23.4-py3-none-manylinux2014_x86_64.whl (199.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.0/199.0 MB\u001b[0m \u001b[31m979.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:06\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nccl-cu12, xgboost\n",
      "Successfully installed nvidia-nccl-cu12-2.23.4 xgboost-2.1.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare the dataset\n",
    "df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "df = df.drop(columns=['student_id'])  # Remove the student_id column\n",
    "df = df.fillna(0)  # Fill missing values with zeros\n",
    "\n",
    "# Train/Validation/Test split\n",
    "train, temp = train_test_split(df, test_size=0.4, random_state=1)\n",
    "val, test = train_test_split(temp, test_size=0.5, random_state=1)\n",
    "\n",
    "# Use DictVectorizer to convert DataFrames to matrices\n",
    "dv = DictVectorizer(sparse=True)\n",
    "X_train = dv.fit_transform(train.drop(columns=['jamb_score']).to_dict(orient='records'))\n",
    "y_train = train['jamb_score'].values\n",
    "X_val = dv.transform(val.drop(columns=['jamb_score']).to_dict(orient='records'))\n",
    "y_val = val['jamb_score'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The feature used for splitting is: study_hours_per_week\n"
     ]
    }
   ],
   "source": [
    "# Train a Decision Tree Regressor with max_depth=1\n",
    "tree = DecisionTreeRegressor(max_depth=1, random_state=1)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# Determine which feature is used for splitting\n",
    "feature_importances = tree.feature_importances_\n",
    "most_important_feature_index = np.argmax(feature_importances)\n",
    "most_important_feature = dv.get_feature_names_out()[most_important_feature_index]\n",
    "\n",
    "print(f\"The feature used for splitting is: {most_important_feature}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on validation dataset: 43.157758977963624\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest model\n",
    "rf = RandomForestRegressor(n_estimators=10, random_state=1, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Calculate RMSE on validation\n",
    "val_predictions = rf.predict(X_val)\n",
    "rmse_val = np.sqrt(np.mean((val_predictions - y_val) ** 2))\n",
    "\n",
    "print(f\"RMSE on validation dataset: {rmse_val}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal n_estimators where RMSE stops improving: 180\n"
     ]
    }
   ],
   "source": [
    "rmse_results = []\n",
    "for n in range(10, 201, 10):\n",
    "    rf = RandomForestRegressor(n_estimators=n, random_state=1, n_jobs=-1)\n",
    "    rf.fit(X_train, y_train)\n",
    "    val_predictions = rf.predict(X_val)\n",
    "    rmse_val = np.sqrt(np.mean((val_predictions - y_val) ** 2))\n",
    "    rmse_results.append(rmse_val)\n",
    "\n",
    "# Determine after which value RMSE stops improving\n",
    "optimal_n_estimators = np.argmax(np.diff(rmse_results)) * 10 + 10  # +10 to get the n_estimators value\n",
    "print(f\"Optimal n_estimators where RMSE stops improving: {optimal_n_estimators}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best max_depth: 10\n"
     ]
    }
   ],
   "source": [
    "best_rmse = float('inf')\n",
    "best_max_depth = None\n",
    "\n",
    "for max_depth in [10, 15, 20, 25]:\n",
    "    for n in range(10, 201, 10):\n",
    "        rf = RandomForestRegressor(n_estimators=n, max_depth=max_depth, random_state=1, n_jobs=-1)\n",
    "        rf.fit(X_train, y_train)\n",
    "        val_predictions = rf.predict(X_val)\n",
    "        rmse_val = np.sqrt(np.mean((val_predictions - y_val) ** 2))\n",
    "\n",
    "        if rmse_val < best_rmse:\n",
    "            best_rmse = rmse_val\n",
    "            best_max_depth = max_depth\n",
    "\n",
    "print(f\"Best max_depth: {best_max_depth}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most important feature is: study_hours_per_week\n"
     ]
    }
   ],
   "source": [
    "# Train a model to get feature importance\n",
    "rf = RandomForestRegressor(n_estimators=10, max_depth=20, random_state=1, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importance\n",
    "importances = rf.feature_importances_\n",
    "most_important_feature_index = np.argmax(importances)\n",
    "most_important_feature = dv.get_feature_names_out()[most_important_feature_index]\n",
    "\n",
    "print(f\"The most important feature is: {most_important_feature}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:42.84835\tval-rmse:44.52338\n",
      "[1]\ttrain-rmse:39.96423\tval-rmse:42.83406\n",
      "[2]\ttrain-rmse:37.91231\tval-rmse:41.62607\n",
      "[3]\ttrain-rmse:36.51126\tval-rmse:41.25491\n",
      "[4]\ttrain-rmse:35.52212\tval-rmse:40.84075\n",
      "[5]\ttrain-rmse:34.77126\tval-rmse:40.71677\n",
      "[6]\ttrain-rmse:34.03898\tval-rmse:40.72669\n",
      "[7]\ttrain-rmse:33.62820\tval-rmse:40.68822\n",
      "[8]\ttrain-rmse:32.94729\tval-rmse:40.81273\n",
      "[9]\ttrain-rmse:32.27703\tval-rmse:40.84939\n",
      "[10]\ttrain-rmse:31.73818\tval-rmse:40.83759\n",
      "[11]\ttrain-rmse:31.31360\tval-rmse:40.80575\n",
      "[12]\ttrain-rmse:30.72949\tval-rmse:40.84238\n",
      "[13]\ttrain-rmse:30.11486\tval-rmse:40.96020\n",
      "[14]\ttrain-rmse:29.43538\tval-rmse:40.98775\n",
      "[15]\ttrain-rmse:29.23018\tval-rmse:41.04798\n",
      "[16]\ttrain-rmse:28.64113\tval-rmse:41.08375\n",
      "[17]\ttrain-rmse:28.42128\tval-rmse:41.15979\n",
      "[18]\ttrain-rmse:28.36245\tval-rmse:41.18138\n",
      "[19]\ttrain-rmse:27.97787\tval-rmse:41.23551\n",
      "[20]\ttrain-rmse:27.52551\tval-rmse:41.28381\n",
      "[21]\ttrain-rmse:27.27774\tval-rmse:41.36930\n",
      "[22]\ttrain-rmse:26.85970\tval-rmse:41.42601\n",
      "[23]\ttrain-rmse:26.82092\tval-rmse:41.41432\n",
      "[24]\ttrain-rmse:26.58525\tval-rmse:41.43111\n",
      "[25]\ttrain-rmse:26.54546\tval-rmse:41.43625\n",
      "[26]\ttrain-rmse:26.11504\tval-rmse:41.45659\n",
      "[27]\ttrain-rmse:25.83180\tval-rmse:41.47884\n",
      "[28]\ttrain-rmse:25.74352\tval-rmse:41.54026\n",
      "[29]\ttrain-rmse:25.52814\tval-rmse:41.54207\n",
      "[30]\ttrain-rmse:25.19051\tval-rmse:41.61678\n",
      "[31]\ttrain-rmse:25.01407\tval-rmse:41.64999\n",
      "[32]\ttrain-rmse:24.74310\tval-rmse:41.83196\n",
      "[33]\ttrain-rmse:24.50093\tval-rmse:41.87240\n",
      "[34]\ttrain-rmse:24.17486\tval-rmse:41.90276\n",
      "[35]\ttrain-rmse:23.71837\tval-rmse:41.90946\n",
      "[36]\ttrain-rmse:23.55978\tval-rmse:41.93019\n",
      "[37]\ttrain-rmse:23.36059\tval-rmse:41.98357\n",
      "[38]\ttrain-rmse:23.01559\tval-rmse:42.04680\n",
      "[39]\ttrain-rmse:22.51622\tval-rmse:42.09129\n",
      "[40]\ttrain-rmse:22.21691\tval-rmse:42.04865\n",
      "[41]\ttrain-rmse:21.95402\tval-rmse:42.03664\n",
      "[42]\ttrain-rmse:21.61541\tval-rmse:42.14595\n",
      "[43]\ttrain-rmse:21.36268\tval-rmse:42.31654\n",
      "[44]\ttrain-rmse:21.23346\tval-rmse:42.30044\n",
      "[45]\ttrain-rmse:21.21565\tval-rmse:42.30722\n",
      "[46]\ttrain-rmse:20.82570\tval-rmse:42.31610\n",
      "[47]\ttrain-rmse:20.56026\tval-rmse:42.30554\n",
      "[48]\ttrain-rmse:20.41518\tval-rmse:42.34045\n",
      "[49]\ttrain-rmse:20.16619\tval-rmse:42.34395\n",
      "[50]\ttrain-rmse:19.90566\tval-rmse:42.31672\n",
      "[51]\ttrain-rmse:19.76122\tval-rmse:42.32735\n",
      "[52]\ttrain-rmse:19.67866\tval-rmse:42.32699\n",
      "[53]\ttrain-rmse:19.31026\tval-rmse:42.36062\n",
      "[54]\ttrain-rmse:19.13879\tval-rmse:42.37273\n",
      "[55]\ttrain-rmse:18.80865\tval-rmse:42.40935\n",
      "[56]\ttrain-rmse:18.62607\tval-rmse:42.40967\n",
      "[57]\ttrain-rmse:18.36591\tval-rmse:42.52177\n",
      "[58]\ttrain-rmse:18.17881\tval-rmse:42.50903\n",
      "[59]\ttrain-rmse:17.93172\tval-rmse:42.55058\n",
      "[60]\ttrain-rmse:17.78802\tval-rmse:42.54742\n",
      "[61]\ttrain-rmse:17.60160\tval-rmse:42.55677\n",
      "[62]\ttrain-rmse:17.31871\tval-rmse:42.57243\n",
      "[63]\ttrain-rmse:17.07422\tval-rmse:42.62503\n",
      "[64]\ttrain-rmse:17.00151\tval-rmse:42.63358\n",
      "[65]\ttrain-rmse:16.80289\tval-rmse:42.65825\n",
      "[66]\ttrain-rmse:16.72052\tval-rmse:42.69443\n",
      "[67]\ttrain-rmse:16.65185\tval-rmse:42.71430\n",
      "[68]\ttrain-rmse:16.47903\tval-rmse:42.73232\n",
      "[69]\ttrain-rmse:16.33637\tval-rmse:42.83029\n",
      "[70]\ttrain-rmse:16.24964\tval-rmse:42.89325\n",
      "[71]\ttrain-rmse:15.99361\tval-rmse:43.00518\n",
      "[72]\ttrain-rmse:15.87691\tval-rmse:43.03962\n",
      "[73]\ttrain-rmse:15.82881\tval-rmse:43.09723\n",
      "[74]\ttrain-rmse:15.74902\tval-rmse:43.11362\n",
      "[75]\ttrain-rmse:15.55190\tval-rmse:43.10072\n",
      "[76]\ttrain-rmse:15.44201\tval-rmse:43.09362\n",
      "[77]\ttrain-rmse:15.14635\tval-rmse:43.16534\n",
      "[78]\ttrain-rmse:14.93209\tval-rmse:43.18029\n",
      "[79]\ttrain-rmse:14.71316\tval-rmse:43.17780\n",
      "[80]\ttrain-rmse:14.65331\tval-rmse:43.21506\n",
      "[81]\ttrain-rmse:14.60812\tval-rmse:43.20548\n",
      "[82]\ttrain-rmse:14.51735\tval-rmse:43.21293\n",
      "[83]\ttrain-rmse:14.39240\tval-rmse:43.23791\n",
      "[84]\ttrain-rmse:14.17319\tval-rmse:43.26724\n",
      "[85]\ttrain-rmse:14.07000\tval-rmse:43.27349\n",
      "[86]\ttrain-rmse:13.87994\tval-rmse:43.32984\n",
      "[87]\ttrain-rmse:13.81474\tval-rmse:43.29409\n",
      "[88]\ttrain-rmse:13.61281\tval-rmse:43.26675\n",
      "[89]\ttrain-rmse:13.45279\tval-rmse:43.25554\n",
      "[90]\ttrain-rmse:13.37213\tval-rmse:43.24201\n",
      "[91]\ttrain-rmse:13.29687\tval-rmse:43.24549\n",
      "[92]\ttrain-rmse:13.24103\tval-rmse:43.25426\n",
      "[93]\ttrain-rmse:13.19399\tval-rmse:43.24337\n",
      "[94]\ttrain-rmse:12.94810\tval-rmse:43.27104\n",
      "[95]\ttrain-rmse:12.77700\tval-rmse:43.28399\n",
      "[96]\ttrain-rmse:12.54410\tval-rmse:43.29006\n",
      "[97]\ttrain-rmse:12.42162\tval-rmse:43.32850\n",
      "[98]\ttrain-rmse:12.37202\tval-rmse:43.33795\n",
      "[99]\ttrain-rmse:12.29305\tval-rmse:43.34291\n",
      "[0]\ttrain-rmse:45.64414\tval-rmse:46.63724\n",
      "[1]\ttrain-rmse:44.26862\tval-rmse:45.58724\n",
      "[2]\ttrain-rmse:43.08569\tval-rmse:44.76209\n",
      "[3]\ttrain-rmse:42.05227\tval-rmse:44.02498\n",
      "[4]\ttrain-rmse:41.10533\tval-rmse:43.40640\n",
      "[5]\ttrain-rmse:40.28309\tval-rmse:42.92195\n",
      "[6]\ttrain-rmse:39.54133\tval-rmse:42.49211\n",
      "[7]\ttrain-rmse:38.87686\tval-rmse:42.15780\n",
      "[8]\ttrain-rmse:38.27674\tval-rmse:41.84104\n",
      "[9]\ttrain-rmse:37.74058\tval-rmse:41.58026\n",
      "[10]\ttrain-rmse:37.26338\tval-rmse:41.35829\n",
      "[11]\ttrain-rmse:36.82810\tval-rmse:41.19143\n",
      "[12]\ttrain-rmse:36.41091\tval-rmse:41.02571\n",
      "[13]\ttrain-rmse:36.01019\tval-rmse:40.90308\n",
      "[14]\ttrain-rmse:35.67454\tval-rmse:40.79701\n",
      "[15]\ttrain-rmse:35.33492\tval-rmse:40.66274\n",
      "[16]\ttrain-rmse:35.01425\tval-rmse:40.60840\n",
      "[17]\ttrain-rmse:34.72687\tval-rmse:40.55942\n",
      "[18]\ttrain-rmse:34.40588\tval-rmse:40.46321\n",
      "[19]\ttrain-rmse:34.16207\tval-rmse:40.42760\n",
      "[20]\ttrain-rmse:33.94837\tval-rmse:40.40272\n",
      "[21]\ttrain-rmse:33.67900\tval-rmse:40.33790\n",
      "[22]\ttrain-rmse:33.44365\tval-rmse:40.25893\n",
      "[23]\ttrain-rmse:33.15283\tval-rmse:40.23702\n",
      "[24]\ttrain-rmse:32.93544\tval-rmse:40.23146\n",
      "[25]\ttrain-rmse:32.76647\tval-rmse:40.16645\n",
      "[26]\ttrain-rmse:32.63384\tval-rmse:40.17172\n",
      "[27]\ttrain-rmse:32.48413\tval-rmse:40.20266\n",
      "[28]\ttrain-rmse:32.34090\tval-rmse:40.20407\n",
      "[29]\ttrain-rmse:32.10350\tval-rmse:40.20207\n",
      "[30]\ttrain-rmse:31.97085\tval-rmse:40.20269\n",
      "[31]\ttrain-rmse:31.73414\tval-rmse:40.22897\n",
      "[32]\ttrain-rmse:31.54401\tval-rmse:40.19830\n",
      "[33]\ttrain-rmse:31.36899\tval-rmse:40.20204\n",
      "[34]\ttrain-rmse:31.24775\tval-rmse:40.23194\n",
      "[35]\ttrain-rmse:31.15313\tval-rmse:40.25736\n",
      "[36]\ttrain-rmse:30.99759\tval-rmse:40.26914\n",
      "[37]\ttrain-rmse:30.85610\tval-rmse:40.26719\n",
      "[38]\ttrain-rmse:30.79344\tval-rmse:40.26957\n",
      "[39]\ttrain-rmse:30.62256\tval-rmse:40.28299\n",
      "[40]\ttrain-rmse:30.48894\tval-rmse:40.26732\n",
      "[41]\ttrain-rmse:30.33833\tval-rmse:40.29323\n",
      "[42]\ttrain-rmse:30.26396\tval-rmse:40.32109\n",
      "[43]\ttrain-rmse:30.19422\tval-rmse:40.32584\n",
      "[44]\ttrain-rmse:30.09094\tval-rmse:40.36338\n",
      "[45]\ttrain-rmse:29.96987\tval-rmse:40.37165\n",
      "[46]\ttrain-rmse:29.86091\tval-rmse:40.38709\n",
      "[47]\ttrain-rmse:29.74442\tval-rmse:40.39932\n",
      "[48]\ttrain-rmse:29.63804\tval-rmse:40.43392\n",
      "[49]\ttrain-rmse:29.53809\tval-rmse:40.42348\n",
      "[50]\ttrain-rmse:29.42464\tval-rmse:40.42217\n",
      "[51]\ttrain-rmse:29.29090\tval-rmse:40.44747\n",
      "[52]\ttrain-rmse:29.18510\tval-rmse:40.44522\n",
      "[53]\ttrain-rmse:29.03115\tval-rmse:40.43013\n",
      "[54]\ttrain-rmse:28.90388\tval-rmse:40.45685\n",
      "[55]\ttrain-rmse:28.84953\tval-rmse:40.45088\n",
      "[56]\ttrain-rmse:28.71980\tval-rmse:40.45935\n",
      "[57]\ttrain-rmse:28.56047\tval-rmse:40.46788\n",
      "[58]\ttrain-rmse:28.52014\tval-rmse:40.48062\n",
      "[59]\ttrain-rmse:28.48999\tval-rmse:40.49604\n",
      "[60]\ttrain-rmse:28.40566\tval-rmse:40.50575\n",
      "[61]\ttrain-rmse:28.28456\tval-rmse:40.51457\n",
      "[62]\ttrain-rmse:28.22862\tval-rmse:40.51808\n",
      "[63]\ttrain-rmse:28.14795\tval-rmse:40.52991\n",
      "[64]\ttrain-rmse:27.95754\tval-rmse:40.52295\n",
      "[65]\ttrain-rmse:27.84888\tval-rmse:40.55196\n",
      "[66]\ttrain-rmse:27.79099\tval-rmse:40.55285\n",
      "[67]\ttrain-rmse:27.60483\tval-rmse:40.55076\n",
      "[68]\ttrain-rmse:27.43626\tval-rmse:40.56419\n",
      "[69]\ttrain-rmse:27.35264\tval-rmse:40.58003\n",
      "[70]\ttrain-rmse:27.14408\tval-rmse:40.58776\n",
      "[71]\ttrain-rmse:26.98608\tval-rmse:40.60545\n",
      "[72]\ttrain-rmse:26.90690\tval-rmse:40.63961\n",
      "[73]\ttrain-rmse:26.84116\tval-rmse:40.64458\n",
      "[74]\ttrain-rmse:26.77990\tval-rmse:40.64569\n",
      "[75]\ttrain-rmse:26.65380\tval-rmse:40.62102\n",
      "[76]\ttrain-rmse:26.46830\tval-rmse:40.61890\n",
      "[77]\ttrain-rmse:26.41999\tval-rmse:40.61790\n",
      "[78]\ttrain-rmse:26.34538\tval-rmse:40.62341\n",
      "[79]\ttrain-rmse:26.26979\tval-rmse:40.62085\n",
      "[80]\ttrain-rmse:26.19196\tval-rmse:40.64646\n",
      "[81]\ttrain-rmse:26.11081\tval-rmse:40.65175\n",
      "[82]\ttrain-rmse:26.00928\tval-rmse:40.66047\n",
      "[83]\ttrain-rmse:25.94863\tval-rmse:40.66914\n",
      "[84]\ttrain-rmse:25.83129\tval-rmse:40.67601\n",
      "[85]\ttrain-rmse:25.77869\tval-rmse:40.69980\n",
      "[86]\ttrain-rmse:25.72397\tval-rmse:40.71420\n",
      "[87]\ttrain-rmse:25.66505\tval-rmse:40.71247\n",
      "[88]\ttrain-rmse:25.50646\tval-rmse:40.70091\n",
      "[89]\ttrain-rmse:25.46492\tval-rmse:40.71010\n",
      "[90]\ttrain-rmse:25.38224\tval-rmse:40.72848\n",
      "[91]\ttrain-rmse:25.25597\tval-rmse:40.75062\n",
      "[92]\ttrain-rmse:25.20408\tval-rmse:40.77304\n",
      "[93]\ttrain-rmse:25.07117\tval-rmse:40.78702\n",
      "[94]\ttrain-rmse:24.99078\tval-rmse:40.78975\n",
      "[95]\ttrain-rmse:24.91495\tval-rmse:40.78298\n",
      "[96]\ttrain-rmse:24.80240\tval-rmse:40.81555\n",
      "[97]\ttrain-rmse:24.75689\tval-rmse:40.81947\n",
      "[98]\ttrain-rmse:24.69412\tval-rmse:40.82907\n",
      "[99]\ttrain-rmse:24.58526\tval-rmse:40.83188\n",
      "RMSE for eta=0.3: 43.342905809394544\n",
      "RMSE for eta=0.1: 40.8318750593964\n",
      "Best eta is 0.1\n"
     ]
    }
   ],
   "source": [
    "# Create DMatrix for XGBoost\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dval = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "# Watchlist for evaluation\n",
    "watchlist = [(dtrain, 'train'), (dval, 'val')]\n",
    "\n",
    "# Train model with eta=0.3\n",
    "params = {\n",
    "    'eta': 0.3,\n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'nthread': 8,\n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "\n",
    "model_03 = xgb.train(params, dtrain, num_boost_round=100, evals=watchlist)\n",
    "\n",
    "# Evaluate RMSE for eta=0.3\n",
    "val_predictions_03 = model_03.predict(dval)\n",
    "rmse_val_03 = np.sqrt(np.mean((val_predictions_03 - y_val) ** 2))\n",
    "\n",
    "# Train model with eta=0.1\n",
    "params['eta'] = 0.1\n",
    "model_01 = xgb.train(params, dtrain, num_boost_round=100, evals=watchlist)\n",
    "\n",
    "# Evaluate RMSE for eta=0.1\n",
    "val_predictions_01 = model_01.predict(dval)\n",
    "rmse_val_01 = np.sqrt(np.mean((val_predictions_01 - y_val) ** 2))\n",
    "\n",
    "print(f\"RMSE for eta=0.3: {rmse_val_03}\")\n",
    "print(f\"RMSE for eta=0.1: {rmse_val_01}\")\n",
    "\n",
    "if rmse_val_03 < rmse_val_01:\n",
    "    print(\"Best eta is 0.3\")\n",
    "elif rmse_val_03 > rmse_val_01:\n",
    "    print(\"Best eta is 0.1\")\n",
    "else:\n",
    "    print(\"Both give equal value\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
